{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e408d2-b40a-424f-b228-a04477a7f110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CNN (convolutional neural network) MNIST examples\n",
    "\n",
    "Wei Li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# random_seed = 123\n",
    "# os.environ[\"PL_GLOBAL_SEED\"] = str(random_seed)\n",
    "# random.seed(random_seed)\n",
    "# np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Wei Li\" -u -t -d -v -p numpy,torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from utils_evaluation import set_all_seeds, set_deterministic, evaluate_epoch_loss, evaluate_epoch_metrics, get_predictions\n",
    "from utils_plotting import plot_accuracy, plot_loss, show_images, plot_confusion_matrix\n",
    "from utils_data import get_dataloaders_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting \n",
    "RANDOM_SEED = 2022\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "set_deterministic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MNIST DATASET \n",
    "##########################\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "# Compose a series of image transformations.\n",
    "transformCompose = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((32, 32)), # Resize the input image to 32x32 pixels.\n",
    "        transforms.ToTensor(),        # Convert the image to a PyTorch tensor, in range [0. 255] to [0.0, 1.0]\n",
    "        transforms.Normalize((0.5,), (0.5,)), # Normalize the tensor image with mean 0.5 and standard deviation 0.5.\n",
    "    ]\n",
    ")\n",
    "# after transformation, pixel value is centered at 0 and range [-1, 1].\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_mnist(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_fraction=0.2,\n",
    "    train_transforms=transformCompose,\n",
    "    test_transforms=transformCompose)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)  # NCHW\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break\n",
    "\n",
    "# len(train_loader) # 93 minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b43ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train batches        : \", train_loader.__len__())\n",
    "print(\"Val batches          : \", valid_loader.__len__())\n",
    "print(\"Test batches        : \", test_loader.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_dataloader(dataloader, num_images=10):\n",
    "    \"\"\"\n",
    "    Extract a specified number of images and labels from a DataLoader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): The DataLoader to extract data from.\n",
    "        num_images (int): Number of images to extract.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of numpy arrays: (images, labels)\n",
    "    \"\"\"\n",
    "    images, labels = next(iter(dataloader))\n",
    "    return images[:num_images].numpy(), labels[:num_images].numpy()\n",
    "\n",
    "train_images, train_labels = extract_data_from_dataloader(train_loader, num_images=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f91bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_images, train_labels, num_images=10, normalize=True, mean=(0.5), std=(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LeNet-5 model\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.convnet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=16*5*5, out_features=120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convnet(x) # NCHW\n",
    "        # x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = torch.flatten(x, 1) #N by CHW        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LR = 0.1\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "# Model, Loss and Optimizer\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "minibatch_loss_list, avg_loss_list,train_loss_list, val_loss_list, train_acc_list, val_acc_list = [],[], [], [], [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # ## FORWARD AND BACK PROP\n",
    "        y_pred = model(features)\n",
    "        loss = criterion(y_pred, targets)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # ## UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "\n",
    "        # ## LOGGING\n",
    "        minibatch_loss_list.append(loss.item())\n",
    "        if not batch_idx % 50:\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} '\n",
    "                  f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
    "                  f'| Loss: {loss:.4f}')\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():  # save memory during inference\n",
    "        ### logging for running average of loss over all traversed minibatches\n",
    "        # avg_loss = torch.mean(torch.FloatTensor(minibatch_loss_list)) \n",
    "        # or the average over most recent minibatches in last epoch\n",
    "        avg_loss = torch.mean(torch.FloatTensor(minibatch_loss_list[-len(train_loader):])) \n",
    "        avg_loss_list.append(avg_loss)\n",
    "\n",
    "        train_loss = evaluate_epoch_loss(model, train_loader, device=device, criterion = nn.CrossEntropyLoss())[1]\n",
    "        val_loss = evaluate_epoch_loss(model, valid_loader, device=device,criterion = nn.CrossEntropyLoss())[1]\n",
    "\n",
    "        train_acc = evaluate_epoch_metrics(model, train_loader, device=device)\n",
    "        val_acc = evaluate_epoch_metrics(model, valid_loader, device=device)\n",
    "\n",
    "        # Print train and test loss along with accuracy\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} '\n",
    "            f'| Train Loss: {train_loss:.4f} '\n",
    "            f'| Valid Loss: {val_loss:.4f} '\n",
    "            f'| Train Acc: {train_acc:.2f}% '\n",
    "            f'| Valid Acc: {val_acc:.2f}% ')\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)        \n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "\n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')\n",
    "\n",
    "print()\n",
    "test_acc = evaluate_epoch_metrics(model, test_loader, device=device)\n",
    "print(f'Test accuracy {test_acc :.2f}')\n",
    "\n",
    "# benchmark:\n",
    "# Epoch: 015/015 | Train Loss: 0.0516 | Valid Loss: 0.0589 | Train Acc: 98.59% | Valid Acc: 98.27% \n",
    "# Test accuracy 98.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "plot_loss(train_loss_list=train_loss_list,\n",
    "              valid_loss_list=val_loss_list,\n",
    "              results_dir=None)\n",
    "plt.show()\n",
    "\n",
    "plot_accuracy(train_acc_list=train_acc_list,\n",
    "              valid_acc_list=val_acc_list,\n",
    "              results_dir=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "test_images, test_labels, test_predictions = get_predictions(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first 10 test images with predictions\n",
    "show_images(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    test_predictions,\n",
    "    num_images=20,\n",
    "    normalize=True,\n",
    "    mean=(0.5),\n",
    "    std=(0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict for MNIST (optional, as it's a direct 0-9 mapping)\n",
    "mnist_label_dict = {i: str(i) for i in range(10)}\n",
    "\n",
    "plot_confusion_matrix(test_labels, test_predictions, mnist_label_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
