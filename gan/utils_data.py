import os, glob
import numpy as np
import pandas as pd
from torchvision import datasets, transforms
import torch
from torch.utils.data import sampler
from torch.utils.data import DataLoader
from torch.utils.data import SubsetRandomSampler
import requests

DATA_DIR = "/Users/wli169/Documents/Work/datasets/"


def preprocess(df, variables, means, stds, cat_labels):
    """
    Scale training data for training in WGANs

    It takes variables to be generated:
    1. if continuous, then normalized
    2. if categorical, then transformed to be one-hot encoding

    It takes context variables:
    1. if continuous, then normalized
    2. if categorical, then coerced to be continous and normalized

    Args:
        df: pandas.DataFrame
            raw training data
        variables:
        means: a list of two lists, first list stores means for continous
            variable, second list for context variable, for df
        stds: a list of two lists, first list stores stds for continous
            variable, second list for context variable, for df
        cat_labels: A list of tensors, where each tensor contains the
                labels of the levels of a categorical variable,
                represented as floating-point numbers.

    Returns:
        x: torch.tensor
            training data to be generated by WGAN;
            including normalized continuous variabels and one-hot encoded
            categorical variables

        context: torch.tensor
            training data to be conditioned on by WGAN;
            these variables are normalized (if they are categorical, they are
            coerced to be continuous).
    """
    x, context = [
        torch.tensor(np.array(df[variables[_]])).to(torch.float)
        for _ in ("continuous", "context")
    ]
    x, context = [(x - m) / s for x, m, s in zip([x, context], means, stds)]
    # normalize x and context variables
    # [x, context], self.means, self.stds each is a list of two lists

    if len(variables["categorical"]) > 0:
        categorical = torch.tensor(
            pd.get_dummies(
                df[variables["categorical"]],
                columns=variables["categorical"],
            ).to_numpy()
        )
        # create a full data matrix (one-hot encoded) for the dummies of categorical variables

        x = torch.cat([x, categorical.to(torch.float)], -1)
        # now the x matrix includes both continuous and (one-hot encoded) categorical random variables

    total = torch.cat([x, context], -1)
    # total is the matrix includes all variables (continuous, categorical, context)
    # where continuous and context are normalized

    if not torch.all(total == total):
        raise RuntimeError(
            "It looks like there are NaNs your data, at least after preprocessing. This is currently not supported!"
        )
    return x, context


def deprocess(x, context, variables, means, stds, cat_labels, cat_dims):
    """
    Unscale tensors from WGAN output to original scale

    Args:
        x: torch.tensor
            Generated data
            note: generated data x include generated (normalized) continuous variables
            and generated one-hot encoded categorical variables.
        context: torch.tensor
            Data conditioned on (normalized context variables)
        variables:
        means: a list of two lists, first list stores means for continous
            variable, second list for context variable, for df
        stds: a list of two lists, first list stores stds for continous
            variable, second list for context variable, for df
        cat_labels: A list of tensors, where each tensor contains the
                labels of the levels of a categorical variable,
                represented as floating-point numbers.
        cat_dims: A list of dimension (number of levels) of each categorical variable

    Returns:
        df: pandas.DataFrame
            DataFrame with data converted back to original scale
    """
    # recall inside preprocess, the x matrix includes both continuous and dummies categorical random variables

    continuous, categorical = x.split((means[0].size(-1), sum(cat_dims)), -1)
    # means[0].size(-1) gives thue number of continous variable
    # sum(self.cat_dims) gives total number of levels for all categorical variables
    # x.split basically decomposes x back into two separate data matricies
    # spllit with -1 indicates that the split should occur along the last dimension of x.

    # denormalized (generated) continuous, and context
    continuous, context = [
        x * s + m for x, m, s in zip([continuous, context], means, stds)
    ]
    # [continuous, context] a list of two tensor array
    # recall and self.means and self.stds, each is a list of two lists (one for continuous, one for context)

    if categorical.size(-1) > 0:
        # if categorical dummy marix is non-empty

        categorical = torch.cat(
            [
                l[torch.multinomial(p, 1)]
                for p, l in zip(categorical.split(cat_dims, -1), cat_labels)
            ],
            -1,
        )
        # revert from the dummy matrix of categorical variable back to the original form of matrix

    df = pd.DataFrame(
        dict(
            zip(
                variables["continuous"]
                + variables["categorical"]
                + variables["context"],
                torch.cat([continuous, categorical, context], -1).detach().t(),
            )
        )
    )
    return df
