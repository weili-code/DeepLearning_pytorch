{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e408d2-b40a-424f-b228-a04477a7f110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## conditional-WGAN (Wasserstein Generative Adversarial Network) LDW examples\n",
    "\n",
    "Wei Li\n",
    "\n",
    "This illustration is a simplied and modified version based on the package https://ds-wgan.readthedocs.io/en/latest/\n",
    "\n",
    "Credits: \n",
    "Susan Athey, Guido Imbens, Jonas Metzger, Evan Munro [2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "# random_seed = 123\n",
    "# os.environ[\"PL_GLOBAL_SEED\"] = str(random_seed)\n",
    "# random.seed(random_seed)\n",
    "# np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Wei Li\n",
      "\n",
      "Last updated: 2024-01-16 12:11:32\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.17\n",
      "IPython version      : 8.12.2\n",
      "\n",
      "numpy: 1.21.5\n",
      "torch: 1.12.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %pip install watermark\n",
    "%load_ext watermark\n",
    "%watermark -a \"Wei Li\" -u -t -d -v -p numpy,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From local helper files\n",
    "from utils_evaluation import (\n",
    "    set_all_seeds,\n",
    "    set_deterministic,\n",
    "    compare_dfs\n",
    ")\n",
    "\n",
    "from utils_data import preprocess, deprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting \n",
    "RANDOM_SEED = 2022\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_all_seeds(RANDOM_SEED)\n",
    "set_deterministic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494df2c0",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "This is data on a job training program (the treatment) that was intended to raise\n",
    "future earnings (the outcome). The income in $\\$1000$ in the year of 1978. The data combines the original experimental data (445 observations) and additional control observations from PSID data, totalling $2675$ observations.\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "%\\begin{array}{ll}\n",
    "\\hline \\text { Variable } & \\text { Description } \\\\\n",
    "\\hline \\text { age } & \\text { Age in years } \\\\\n",
    "\\text { educ } & \\text { Years of education } \\\\\n",
    "\\text { black } & 1=\\text { Black; } 0 \\text { otherwise } \\\\\n",
    "\\text { hisp } & 1=\\text { Hispanic; } 0 \\text { otherwise } \\\\\n",
    "\\text { married } & 1=\\text { married; } 0 \\text { otherwise } \\\\\n",
    "\\text { nodegr } & 1=\\text { no degree; } 0 \\text { otherwise } \\\\\n",
    "\\text { re74 } & 1974 \\text { income}\\\\\n",
    "\\text { re75 } & 1975 \\text { income}  \\\\\n",
    "\\text { re78 } & 1978 \\text { income} \\\\\n",
    "\\text { treat } & 1=\\text { received treatment; } 0 \\text { otherwise } \\\\\n",
    "\\hline\n",
    "%\\end{array}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4b4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(\"../data/psid_LDW_merged.csv\").drop([\"u74\", \"u75\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067da460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegr</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9930.0460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3595.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24909.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7506.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.7899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   T  age  educ  black  hisp  married  nodegr  re74  re75        re78\n",
       "0  1   37    11      1     0        1       1   0.0   0.0   9930.0460\n",
       "1  1   22     9      0     1        0       1   0.0   0.0   3595.8940\n",
       "2  1   30    12      1     0        0       0   0.0   0.0  24909.4500\n",
       "3  1   27    11      1     0        0       1   0.0   0.0   7506.1460\n",
       "4  1   33     8      1     0        0       1   0.0   0.0    289.7899"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf161d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 T          age         educ        black         hisp  \\\n",
      "count  2675.000000  2675.000000  2675.000000  2675.000000  2675.000000   \n",
      "mean      0.069159    34.225794    11.994393     0.291589     0.034393   \n",
      "std       0.253772    10.499842     3.053556     0.454579     0.182269   \n",
      "min       0.000000    17.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000    25.000000    10.000000     0.000000     0.000000   \n",
      "50%       0.000000    32.000000    12.000000     0.000000     0.000000   \n",
      "75%       0.000000    43.500000    14.000000     1.000000     0.000000   \n",
      "max       1.000000    55.000000    17.000000     1.000000     1.000000   \n",
      "\n",
      "           married       nodegr           re74           re75           re78  \n",
      "count  2675.000000  2675.000000    2675.000000    2675.000000    2675.000000  \n",
      "mean      0.819439     0.333084   18230.003096   17850.893766   20502.375641  \n",
      "std       0.384726     0.471404   13722.251526   13877.777180   15632.519749  \n",
      "min       0.000000     0.000000       0.000000       0.000000       0.000000  \n",
      "25%       1.000000     0.000000    8816.700600    7605.290300    9243.400900  \n",
      "50%       1.000000     0.000000   17437.475000   17008.065000   19432.104000  \n",
      "75%       1.000000     1.000000   25470.468000   25583.709500   28815.668000  \n",
      "max       1.000000     1.000000  137148.680000  156653.230000  121173.580000  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2490,  185]), array([ 331, 2344]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats for treatment\n",
    "print(data_all.describe())\n",
    "print()\n",
    "\n",
    "np.bincount(data_all[\"T\"]), np.bincount(data_all[\"re78\"] > 0)\n",
    "# counts of 0/1\n",
    "# (array([2490,  185]), array([ 331, 2344]))\n",
    "# about 7% enrolled in the training program\n",
    "# about 13% unemployed in 1978"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a68b4",
   "metadata": {},
   "source": [
    "We shall consider generating variables $X$=(\"age\", \"educ\", \"re74\", \"re75\", \"re78\"), based on the treatment status. We use Wasserstein GAN with gradient penalty to achieve this task.\n",
    "This exercise contains two stages:\n",
    "\n",
    "1. Train conditional GAN based on a balanced data `data_balanced`.\n",
    "2. Generate X given T based on the `data_all` using the trained GAN from 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141578c",
   "metadata": {},
   "source": [
    "The dataframe `data_balanced` is obtained by sampling treated and controls with similar probability from `data_all`. We will train a WGAN on `data_balanced`, which makes sure the quality of the generated outcomes is similar for both treatment groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "172ad944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2675, 10), (5350, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced = data_all.sample(\n",
    "    2 * len(data_all),\n",
    "    weights=(1 - data_all[\"T\"].mean()) * data_all[\"T\"]\n",
    "    + data_all[\"T\"].mean() * (1 - data_all[\"T\"]),\n",
    "    replace=True,\n",
    ")  # balanced df for training\n",
    "\n",
    "data_all.shape, data_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438dec5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_all[\"T\"].hist(bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cba6f3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_balanced[\"T\"].hist(bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639d6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X | t\n",
    "continuous_vars = [\"age\", \"educ\", \"re74\", \"re75\", \"re78\"]\n",
    "continuous_lower_bounds = {\"age\": 17, \"educ\": 0, \"re74\": 0, \"re75\": 0, \"re78\": 0}\n",
    "continuous_upper_bounds = dict()  # none\n",
    "categorical_vars = [\"black\", \"hisp\", \"married\", \"nodegr\"]\n",
    "context_vars = [\"T\"]\n",
    "\n",
    "variables = dict(\n",
    "    continuous=continuous_vars,\n",
    "    categorical=categorical_vars,\n",
    "    context=context_vars,\n",
    ")\n",
    "\n",
    "cat_dims = [2, 2, 2, 2]  # List of dimension (number of levels) of each categorical variable\n",
    "d_context = 1  # number of context variables\n",
    "d_cont = 5  # number of continuous variables\n",
    "d_x = 5 + 8\n",
    "# d_x: (output dim) total number of continuous variables+ numer of variables (total levels) in the dummy categorical matrix\n",
    "generator_d_noise = d_x  # (output dim)  total dim of continous and categorical levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241f3f7",
   "metadata": {},
   "source": [
    "Our generator shall take in normalized dataset during the training process. Specifically,\n",
    "\n",
    "It takes variables to be generated:\n",
    "1. if continuous, then normalized\n",
    "2. if categorical, then transformed to be one-hot encoding\n",
    "\n",
    "It takes context variables:\n",
    "1. if continuous, then normalized\n",
    "2. if categorical, then coerced to be continous and normalized\n",
    "\n",
    "When generating the data, we shall take transformed data as input for the trained generator, then de-transform the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74bceb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous, context = [\n",
    "    torch.tensor(np.array(data_balanced[variables[_]])).to(torch.float)\n",
    "    for _ in (\"continuous\", \"context\")\n",
    "]\n",
    "# create continuous, and context variables as torch.tensor from the data_balanced\n",
    "# both continuous and context are returned as tensor matrix, each shape (N, features)\n",
    "\n",
    "# treat all context variables as continuous variables for normalization\n",
    "cont_means = [x.mean(0, keepdim=True) for x in (continuous, context)]\n",
    "# torch.mean compute the mean along 0 axis, output is a list of two lists\n",
    "# first list stores means for continous variable, second list for context variable\n",
    "\n",
    "cont_stds = [x.std(0, keepdim=True) + 1e-5 for x in (continuous, context)]\n",
    "\n",
    "cat_labels = [\n",
    "    torch.tensor(pd.get_dummies(data_balanced[v]).columns.to_numpy()).to(torch.float)\n",
    "    for v in variables[\"categorical\"]\n",
    "]\n",
    "# cat_labels: A list of tensors, where each tensor contains the\n",
    "# labels of the levels of a categorical variable, represented as floating-point numbers.\n",
    "# e.g. \n",
    "# for a categorical variable having 3 (numeric) levels, 5, 6, 7, pd.get_dummies(df[v]).columns.to_numpy()\n",
    "# will return np.array [5, 6, 7]\n",
    "# so cat_labels[0] gives tensor([5., 6., 7.]) the numerical label for this categorical variable\n",
    "\n",
    "\n",
    "cont_bounds = [\n",
    "    [\n",
    "        continuous_lower_bounds[v] if v in continuous_lower_bounds.keys() else -1e8\n",
    "        for v in continuous_vars\n",
    "    ],\n",
    "    [\n",
    "        continuous_upper_bounds[v] if v in continuous_upper_bounds.keys() else 1e8\n",
    "        for v in continuous_vars\n",
    "    ],\n",
    "]\n",
    "\n",
    "cont_bounds = (torch.tensor(cont_bounds).to(torch.float) - cont_means[0]) / cont_stds[0]\n",
    "# cont_bounds: torch.tensor\n",
    "#     formatted lower and upper bounds of continuous variables\n",
    "#     (formatted by normalizing the bounds by mean, and stds)\n",
    "#     a tensor of size 2 by the number of continuous variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2f6329",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic_d_hidden = [128, 128, 128]\n",
    "critic_dropout = 0\n",
    "critic_steps = (\n",
    "    15  # Number of critic training steps taken for each generator training step\n",
    ")\n",
    "critic_lr = 1e-3\n",
    "critic_gp_factor = 5 # gradient penalty weight\n",
    "\n",
    "generator_d_hidden = [128, 128, 128]\n",
    "generator_dropout = 0.1\n",
    "generator_lr = 1e-3\n",
    "\n",
    "max_epochs = 1000\n",
    "batch_size = 32\n",
    "test_set_size = 200\n",
    "save_every = 100\n",
    "print_every = 200\n",
    "load_checkpoint = None\n",
    "save_checkpoint = None\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b7d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    torch.nn.Module class for generator network in WGAN\n",
    "\n",
    "    Generator is multi-layer FNN outputing logits.\n",
    "    Then on the logits:\n",
    "        for categorical variables: do a softmax.\n",
    "        for continuous variables: simply taking the final values output from\n",
    "        last hidden layer by truncating by the lower/upper bounds.\n",
    "\n",
    "    Attrs:\n",
    "        cont_bounds: torch.tensor\n",
    "            formatted lower and upper bounds of continuous variables\n",
    "            (i.e. normalized)\n",
    "        cat_dims: list\n",
    "            Dimension of levels for each categorical variable\n",
    "        d_cont: int\n",
    "            Total dimension of continuous variables\n",
    "        d_cat: int\n",
    "            Total dimension of categorical variables\n",
    "        d_noise: int\n",
    "            Dimension of noise input to generator\n",
    "        layers: torch.nn.ModuleList\n",
    "            Dense neural network layers making up the generator\n",
    "        dropout: torch.nn.Dropout\n",
    "            Dropout layer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cont_bounds = cont_bounds\n",
    "        self.cat_dims = cat_dims\n",
    "        self.d_cont = self.cont_bounds.size(-1)  # dim of continuous variables\n",
    "        self.d_cat = sum(cat_dims)  # dim of categorical levels\n",
    "        self.d_noise = generator_d_noise\n",
    "        # dim of the noise:\n",
    "        # Default sets to the output dimension of the generator\n",
    "        # (output dim, i.e., total dim of continous and categorical levels)\n",
    "\n",
    "        d_in = [self.d_noise + d_context] + generator_d_hidden\n",
    "        # d_in: =a list of input dimension in each layer\n",
    "        # the input size of 1st layer is the total dim of (both continuous, categorical levels\n",
    "        # and the context variables)\n",
    "\n",
    "        d_out = generator_d_hidden + [self.d_cont + self.d_cat]\n",
    "        # d_out: =a list of output dimension in each layer\n",
    "\n",
    "        self.layers = nn.ModuleList([nn.Linear(i, o) for i, o in zip(d_in, d_out)])\n",
    "        # e.g., four hidden layer, then\n",
    "        # it returns like (input dim, 128),(128, 128), (128, 128) and (128, output dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(generator_dropout)\n",
    "\n",
    "    def _transform(self, hidden):\n",
    "        # This function is only used in the output layer\n",
    "        # for categorical variables: do a softmax.\n",
    "        # for continuous variables: simply taking the final values output from\n",
    "        # last hidden layer by truncating by the lower/upper bounds.\n",
    "\n",
    "        continuous, categorical = hidden.split([self.d_cont, self.d_cat], -1)\n",
    "\n",
    "        if continuous.size(-1) > 0:  # apply bounds to continuous\n",
    "            bounds = self.cont_bounds.to(hidden.device)\n",
    "            continuous = (\n",
    "                torch.stack([continuous, bounds[0:1].expand_as(continuous)])\n",
    "                .max(0)\n",
    "                .values\n",
    "            )\n",
    "            continuous = (\n",
    "                torch.stack([continuous, bounds[1:2].expand_as(continuous)])\n",
    "                .min(0)\n",
    "                .values\n",
    "            )\n",
    "\n",
    "            # continuos is sample size by the number of continuous variables\n",
    "            # now it contains the trimmed values according to the lower and upper bound\n",
    "\n",
    "        if categorical.size(-1) > 0:  # renormalize categorical\n",
    "            # for categorical variable, we convert the catergorical levels matrix\n",
    "            # to probability distribution using softmax\n",
    "\n",
    "            categorical = torch.cat(\n",
    "                [F.softmax(x, -1) for x in categorical.split(self.cat_dims, -1)], -1\n",
    "            )\n",
    "            # categorical has size= sample size by number of all categorical levels\n",
    "            # (if each categorical variable takes only 2 levels, then\n",
    "            # number of all categorical levels= 2* number of categorical variables)\n",
    "            # the entries for all the levels of the same categorical variable sum up to 1\n",
    "\n",
    "        return torch.cat([continuous, categorical], -1)\n",
    "        # the final return is a tensor of size =\n",
    "        # sample size by (total number of continuous variables + number of all categorical levels)\n",
    "\n",
    "    def forward(self, context):\n",
    "        \"\"\"\n",
    "        Run generator model\n",
    "\n",
    "        Args\n",
    "            context: torch.tensor\n",
    "                Variables to condition on\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor (sample size, dim of output)\n",
    "        \"\"\"\n",
    "        noise = torch.randn(context.size(0), self.d_noise).to(context.device)\n",
    "        # noise size = sample size by output dimension of the generator\n",
    "\n",
    "        x = torch.cat([noise, context], -1)\n",
    "        # the input size is output dimension+ the dimension of the context\n",
    "        # the noise is the input noise in the generator\n",
    "\n",
    "        for layer in self.layers[:-1]:\n",
    "            # from input layer to the last layer before output layer\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "\n",
    "        # the x returned in the last for loop will be\n",
    "        # dim= (sample size, dim of output)\n",
    "        return self._transform(self.layers[-1](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e256a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \"\"\"\n",
    "    torch.nn.Module for critic in WGAN framework\n",
    "\n",
    "    Attrs:\n",
    "        layers: torch.nn.ModuleList\n",
    "            Dense neural network making up the critic\n",
    "        dropout: torch.nn.Dropout\n",
    "            Dropout layer applied between each of hidden layers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        d_in = [d_x + d_context] + critic_d_hidden\n",
    "        d_out = critic_d_hidden + [\n",
    "            1\n",
    "        ]  # add one because output layer has one output\n",
    "        self.layers = nn.ModuleList([nn.Linear(i, o) for i, o in zip(d_in, d_out)])\n",
    "\n",
    "        self.dropout = nn.Dropout(critic_dropout)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        \"\"\"\n",
    "        Run critic model\n",
    "        output logits (univariate)\n",
    "\n",
    "        Args:\n",
    "            x: torch.tensor\n",
    "                Real or generated data\n",
    "            context: torch.tensor\n",
    "                Data conditioned on\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor shape (sample size)\n",
    "        \"\"\"\n",
    "\n",
    "        x = torch.cat([x, context], -1)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "\n",
    "        # The output will be just one scalar value for each data example\n",
    "        return self.layers[-1](x)\n",
    "\n",
    "    def gradient_penalty(self, x, x_hat, context):\n",
    "        \"\"\"\n",
    "        Calculate gradient penalty\n",
    "\n",
    "        Args:\n",
    "            x: torch.tensor\n",
    "                real data\n",
    "            x_hat: torch.tensor\n",
    "                generated data\n",
    "            context: torch.tensor\n",
    "                context data\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor\n",
    "        \"\"\"\n",
    "\n",
    "        alpha = torch.rand(x.size(0)).unsqueeze(1).to(x.device)\n",
    "        interpolated = x * alpha + x_hat * (1 - alpha)\n",
    "        interpolated = torch.autograd.Variable(\n",
    "            interpolated.detach(), requires_grad=True\n",
    "        )\n",
    "        # the combination of detach() and requires_grad=True allows us to\n",
    "        # reset the gradient computation history for interpolated. We detach it\n",
    "        # from its history (to ignore gradients with respect to the original x and x_hat generation)\n",
    "        # and then specify that we want to track gradients for future operations involving the interpolated tensor.\n",
    "\n",
    "        critic = self(interpolated, context)\n",
    "        # similar to calling of critic.forward(interpolated, context)\n",
    "\n",
    "        gradients = torch.autograd.grad(\n",
    "            critic,\n",
    "            interpolated,\n",
    "            torch.ones_like(critic),\n",
    "            retain_graph=True,\n",
    "            create_graph=True,\n",
    "            only_inputs=True,\n",
    "        )[0]\n",
    "\n",
    "        penalty = F.relu(gradients.norm(2, dim=1) - 1).mean()  # one-sided\n",
    "\n",
    "        return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62bec9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "critic = Critic()\n",
    "\n",
    "opt_generator = torch.optim.Adam(generator.parameters(), lr=generator_lr)\n",
    "opt_critic = torch.optim.Adam(critic.parameters(), lr=critic_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc69ffae",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82cb70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, critic, x, context, device, penalty=None):\n",
    "    \"\"\"\n",
    "    Function for training generator and critic in conditional WGAN-GP\n",
    "\n",
    "    Args:\n",
    "        generator: Generator network to be trained\n",
    "        critic: Critic network to be trained\n",
    "        x: torch.tensor\n",
    "            Training data for generated data\n",
    "        context: torch.tensor\n",
    "            Data conditioned on for generating data\n",
    "        penalty: an optional penalty for generator (not the gradient penalty)\n",
    "    \"\"\"\n",
    "    # setup training objects\n",
    "\n",
    "    start_epoch, step, description, device, t = 0, 1, \"\", device, time()\n",
    "\n",
    "    generator.to(device), critic.to(device)\n",
    "\n",
    "    # load data\n",
    "    train_batches, test_batches = data.random_split(\n",
    "        data.TensorDataset(x, context),\n",
    "        (x.size(0) - test_set_size, test_set_size),\n",
    "    )\n",
    "    # train_batches[i] gives a tuple for the i-th example consisting of two elements,\n",
    "    # one is from x, the other one is from context.\n",
    "\n",
    "    train_batches, test_batches = (\n",
    "        data.DataLoader(d, batch_size, shuffle=True)\n",
    "        for d in (train_batches, test_batches)\n",
    "    )\n",
    "\n",
    "    # load checkpoints\n",
    "    if load_checkpoint:\n",
    "        # load_checkpoint: Filepath to existing model weights to start training from.\n",
    "        cp = torch.load(load_checkpoint)\n",
    "        generator.load_state_dict(cp[\"generator_state_dict\"])\n",
    "        opt_generator.load_state_dict(cp[\"opt_generator_state_dict\"])\n",
    "        critic.load_state_dict(cp[\"critic_state_dict\"])\n",
    "        opt_critic.load_state_dict(cp[\"opt_critic_state_dict\"])\n",
    "        start_epoch, step = cp[\"epoch\"], cp[\"step\"]\n",
    "        #  step refers to each iteration for minibatch\n",
    "\n",
    "    # start training\n",
    "    try:\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "            # train loop\n",
    "            WD_train, n_batches = 0, 0\n",
    "            # WD_train stores average WD-distance per epoch over minibatches\n",
    "            # n_batches update only when updating critic\n",
    "\n",
    "            for x, context in train_batches:\n",
    "                x, context = x.to(device), context.to(device)\n",
    "                generator_update = step % critic_steps == 0\n",
    "                # note: step increments for each minibatch\n",
    "                # generator_update is True or False\n",
    "\n",
    "                for par in critic.parameters():\n",
    "                    par.requires_grad = not generator_update\n",
    "                for par in generator.parameters():\n",
    "                    par.requires_grad = generator_update\n",
    "\n",
    "                if generator_update:\n",
    "                    generator.zero_grad()\n",
    "                else:\n",
    "                    critic.zero_grad()\n",
    "\n",
    "                x_hat = generator(context)\n",
    "                critic_x_hat = critic(x_hat, context).mean()\n",
    "\n",
    "                if not generator_update:\n",
    "                    # if this step is for critic update\n",
    "                    critic_x = critic(x, context).mean()\n",
    "                    WD = critic_x - critic_x_hat\n",
    "                    loss = -WD  # minimization problem\n",
    "                    loss += critic_gp_factor * critic.gradient_penalty(\n",
    "                        x, x_hat, context\n",
    "                    )\n",
    "                    # recall: penalty = relu(gradients_2norm - 1)\n",
    "                    loss.backward()\n",
    "                    opt_critic.step()\n",
    "                    WD_train += WD.item()\n",
    "                    n_batches += 1\n",
    "                else:\n",
    "                    # if this step is for generator\n",
    "                    loss = -critic_x_hat  # minimization problem\n",
    "                    if penalty is not None:\n",
    "                        # penalty is an optional penalty for generator (not GP)\n",
    "                        loss += penalty(x_hat, context)\n",
    "                    loss.backward()\n",
    "                    opt_generator.step()\n",
    "\n",
    "                step += 1\n",
    "\n",
    "            WD_train /= n_batches\n",
    "            # average WD-distance over minibatches for each epoch\n",
    "\n",
    "            # test loop\n",
    "            WD_test, n_batches = 0, 0\n",
    "            for x, context in test_batches:\n",
    "                x, context = x.to(device), context.to(device)\n",
    "                with torch.no_grad():\n",
    "                    x_hat = generator(context)\n",
    "                    critic_x_hat = critic(x_hat, context).mean()\n",
    "                    critic_x = critic(x, context).mean()\n",
    "                    WD_test += (critic_x - critic_x_hat).item()\n",
    "                    n_batches += 1\n",
    "            WD_test /= n_batches\n",
    "            # average WD-distance over minibatches for each epoch\n",
    "\n",
    "            # diagnostics\n",
    "            if epoch % print_every == 0:\n",
    "                description = \"epoch {} | WD_test {} | WD_train {} | sec passed {} |\".format(\n",
    "                    epoch,\n",
    "                    round(WD_test, 2),\n",
    "                    round(WD_train, 2),\n",
    "                    round(time() - t),\n",
    "                )\n",
    "                print(description)\n",
    "                t = time()\n",
    "            if save_checkpoint and epoch % save_every == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"step\": step,\n",
    "                        \"generator_state_dict\": generator.state_dict(),\n",
    "                        \"critic_state_dict\": critic.state_dict(),\n",
    "                        \"opt_generator_state_dict\": opt_generator.state_dict(),\n",
    "                        \"opt_critic_state_dict\": opt_critic.state_dict(),\n",
    "                    },\n",
    "                    save_checkpoint,\n",
    "                )\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"exited gracefully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e747407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | WD_test 2.25 | WD_train 1.99 | sec passed 0 |\n",
      "epoch 200 | WD_test 0.19 | WD_train 0.25 | sec passed 48 |\n",
      "epoch 400 | WD_test 0.19 | WD_train 0.2 | sec passed 48 |\n",
      "epoch 600 | WD_test 0.27 | WD_train 0.21 | sec passed 49 |\n",
      "epoch 800 | WD_test 0.08 | WD_train 0.13 | sec passed 48 |\n"
     ]
    }
   ],
   "source": [
    "x, context = preprocess(data_balanced, variables, cont_means, cont_stds, cat_labels)\n",
    "\n",
    "train(generator, critic, x, context, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5ad69",
   "metadata": {},
   "source": [
    "### Generator data\n",
    "\n",
    "We generate the data based on the original `data_all`. Note that WGAN was trained on `data_balanced`, the balanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fd1b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(generator, df, variables, means, stds, cat_labels):\n",
    "    \"\"\"\n",
    "    Replaces columns in DataFrame with that generated by the generator, of\n",
    "    size equal to the number of rows in the DataFrame that is passed\n",
    "\n",
    "    Args:\n",
    "        df: pandas.DataFrame\n",
    "            Must contain columns generated by the generator,\n",
    "            listed in self.variables[\"continuous\"] and\n",
    "            self.variables[\"categorical\"]\n",
    "        generator: Trained generator for simulating data\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "            Original DataFrame with columns replaced by generated data where possible.\n",
    "    \"\"\"\n",
    "    # replaces columns in df with data from generator wherever possible\n",
    "    generator.to(\"cpu\")\n",
    "    original_columns = df.columns\n",
    "    x, context = preprocess(df, variables, means, stds, cat_labels)\n",
    "\n",
    "    # context variables are being conditioned\n",
    "    x_hat = generator(context)  # generated x variables\n",
    "    # x_hat shape: (sample size, dim of output)\n",
    "\n",
    "    df_hat = deprocess(x_hat, context, variables, means, stds, cat_labels, cat_dims)  # generated DataFrame\n",
    "\n",
    "    updated = variables[\"continuous\"] + variables[\"categorical\"]\n",
    "    not_updated = [col for col in list(df_hat.columns) if col not in updated]\n",
    "\n",
    "    df_hat = df_hat.drop(not_updated, axis=1).reset_index(drop=True)\n",
    "    # df_hat is DataFrame for all generated variables\n",
    "\n",
    "    df = df.drop(updated, axis=1).reset_index(drop=True)\n",
    "    # df is DataFrame for all variables that are not updated\n",
    "\n",
    "    return df_hat.join(df)[original_columns]\n",
    "\n",
    "\n",
    "def predict(critic, df, variables, means, stds, cat_labels, colname=\"critic\"):\n",
    "    \"\"\"\n",
    "    Adds column with critic output for each row the provided Dataframe\n",
    "\n",
    "    Args:\n",
    "        critic: trained critic\n",
    "        df: pandas.DataFrame\n",
    "        colname: str\n",
    "            Name of column to add to df with critic output value\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "    \"\"\"\n",
    "    critic.to(\"cpu\")\n",
    "    x, context = preprocess(df, variables, means, stds, cat_labels)\n",
    "    c = critic(x, context).detach()\n",
    "    # # The output will be just one shape=sample size by one\n",
    "\n",
    "    if colname in list(df.columns):\n",
    "        df = df.drop(colname, axis=1)\n",
    "    # insert at the beginining of df\n",
    "    df.insert(0, colname, c[:, 0].numpy())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a87ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data with conditional WGANs\n",
    "\n",
    "size_gen = int(1e4)\n",
    "\n",
    "# generate data for X given t:\n",
    "data_generated = generate(\n",
    "    generator,\n",
    "    data_all.sample(size_gen, replace=True),\n",
    "    variables,\n",
    "    cont_means,\n",
    "    cont_stds,\n",
    "    cat_labels,\n",
    ")\n",
    "\n",
    "data_generated_crt = predict(\n",
    "    critic,\n",
    "    data_generated,\n",
    "    variables,\n",
    "    cont_means,\n",
    "    cont_stds,\n",
    "    cat_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3abbccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>T</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>nodegr</th>\n",
       "      <th>re74</th>\n",
       "      <th>re75</th>\n",
       "      <th>re78</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.601311</td>\n",
       "      <td>0</td>\n",
       "      <td>24.328287</td>\n",
       "      <td>12.092354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15643.915039</td>\n",
       "      <td>16247.792969</td>\n",
       "      <td>21787.371094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.473352</td>\n",
       "      <td>0</td>\n",
       "      <td>31.708416</td>\n",
       "      <td>10.871608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20510.244141</td>\n",
       "      <td>37129.464844</td>\n",
       "      <td>26642.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.487573</td>\n",
       "      <td>0</td>\n",
       "      <td>25.988960</td>\n",
       "      <td>14.800676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15234.211914</td>\n",
       "      <td>21058.093750</td>\n",
       "      <td>28569.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.223047</td>\n",
       "      <td>0</td>\n",
       "      <td>44.756794</td>\n",
       "      <td>7.156450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5232.243652</td>\n",
       "      <td>4344.026367</td>\n",
       "      <td>7029.763672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.370890</td>\n",
       "      <td>0</td>\n",
       "      <td>39.281780</td>\n",
       "      <td>14.896605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20025.189453</td>\n",
       "      <td>23652.384766</td>\n",
       "      <td>33528.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.940316</td>\n",
       "      <td>0</td>\n",
       "      <td>27.118366</td>\n",
       "      <td>10.672419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11141.666992</td>\n",
       "      <td>8403.476562</td>\n",
       "      <td>11559.231445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4.298130</td>\n",
       "      <td>0</td>\n",
       "      <td>50.993561</td>\n",
       "      <td>15.864401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34246.683594</td>\n",
       "      <td>45862.937500</td>\n",
       "      <td>50767.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.821592</td>\n",
       "      <td>0</td>\n",
       "      <td>28.709129</td>\n",
       "      <td>12.330804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11839.538086</td>\n",
       "      <td>4605.818359</td>\n",
       "      <td>6998.097656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4.128135</td>\n",
       "      <td>1</td>\n",
       "      <td>26.629051</td>\n",
       "      <td>11.801432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4256.816895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11841.806641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.202809</td>\n",
       "      <td>0</td>\n",
       "      <td>53.486992</td>\n",
       "      <td>12.186857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14650.651367</td>\n",
       "      <td>12064.408203</td>\n",
       "      <td>22529.898438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     critic  T        age       educ  black  hisp  married  nodegr  \\\n",
       "0 -5.601311  0  24.328287  12.092354    0.0   0.0      1.0     0.0   \n",
       "1 -5.473352  0  31.708416  10.871608    0.0   1.0      1.0     1.0   \n",
       "2 -5.487573  0  25.988960  14.800676    0.0   0.0      1.0     0.0   \n",
       "3 -5.223047  0  44.756794   7.156450    1.0   0.0      0.0     1.0   \n",
       "4 -5.370890  0  39.281780  14.896605    0.0   0.0      1.0     0.0   \n",
       "5 -5.940316  0  27.118366  10.672419    1.0   0.0      0.0     1.0   \n",
       "6 -4.298130  0  50.993561  15.864401    0.0   0.0      1.0     0.0   \n",
       "7 -5.821592  0  28.709129  12.330804    1.0   0.0      0.0     0.0   \n",
       "8 -4.128135  1  26.629051  11.801432    1.0   0.0      0.0     0.0   \n",
       "9 -5.202809  0  53.486992  12.186857    0.0   0.0      1.0     0.0   \n",
       "\n",
       "           re74          re75          re78  \n",
       "0  15643.915039  16247.792969  21787.371094  \n",
       "1  20510.244141  37129.464844  26642.980469  \n",
       "2  15234.211914  21058.093750  28569.986328  \n",
       "3   5232.243652   4344.026367   7029.763672  \n",
       "4  20025.189453  23652.384766  33528.437500  \n",
       "5  11141.666992   8403.476562  11559.231445  \n",
       "6  34246.683594  45862.937500  50767.046875  \n",
       "7  11839.538086   4605.818359   6998.097656  \n",
       "8   4256.816895      0.000000  11841.806641  \n",
       "9  14650.651367  12064.408203  22529.898438  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generated_crt.shape\n",
    "data_generated_crt.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0ea22",
   "metadata": {},
   "source": [
    "### Check generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88e38f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------comparison of means-------------\n",
      "T               0                  1         \n",
      "source       fake      real     fake     real\n",
      "age         36.57     34.85    26.96    25.82\n",
      "educ        11.96     12.12    10.52    10.35\n",
      "black        0.27      0.25     0.82     0.84\n",
      "hisp         0.05      0.03     0.08     0.06\n",
      "married      0.88      0.87     0.17     0.19\n",
      "nodegr       0.32      0.31     0.69     0.71\n",
      "re74     19715.49  19428.75  1684.33  2095.57\n",
      "re75     19017.44  19063.34  1100.54  1532.06\n",
      "re78     21809.35  21553.92  6358.38  6349.14\n",
      "-------------comparison of stds-------------\n",
      "T               0                  1         \n",
      "source       fake      real     fake     real\n",
      "age         10.16     10.44     7.02     7.16\n",
      "educ         2.61      3.08     1.63     2.01\n",
      "black        0.44      0.43     0.38     0.36\n",
      "hisp         0.21      0.18     0.27     0.24\n",
      "married      0.32      0.34     0.38     0.39\n",
      "nodegr       0.47      0.46     0.46     0.46\n",
      "re74     14022.47  13406.88  4381.14  4886.62\n",
      "re75     13974.89  13596.95  2884.80  3219.25\n",
      "re78     16293.87  15555.35  7863.97  7867.40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAEXCAYAAACwMQ2lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcSklEQVR4nO3dfXDU9b328Wt380QgiRIGDpEQQquFGjlgQqeVKFopngK26gy2FKwPFOQ5kXNbxKcKCqmnDqVTSzQ5HaSlCHpX7oqtaLRFQbRCEKHSAYlKomIpVhIwsEl2v/cfPck5OTxlk+/mt78v79fMTmW7ufazyX72yi/Z3QSMMUYAAMAZQa8HAAAAdlHuAAA4hnIHAMAxlDsAAI6h3AEAcAzlDgCAYyh3AAAcQ7kDAOAYyh0AAMdQ7gAAOCZhy33FihXKz89XWlqaCgsLtXnzZq9HaqesrEwjR45URkaG+vbtq+uuu0579+71eqyzKisrUyAQUGlpqdejnNJHH32kKVOmKDs7W+np6Ro+fLiqq6u9HqudlpYW3XvvvcrPz1ePHj00ePBgLV68WNFo1OvRfC3Rd15i7+OBnY8Tk4DWrl1rkpOTTWVlpdmzZ48pKSkxPXv2NAcOHPB6tDbXXHONWblypfnLX/5idu7cacaPH28GDhxojh075vVop/Xmm2+aQYMGmWHDhpmSkhKvxznJP/7xD5OXl2duueUW8+c//9m8//775qWXXjL79+/3erR2HnroIZOdnW2ee+458/7775unn37a9OrVyyxfvtzr0XzLDztvDHtvGzsfPwlZ7l/5ylfMjBkz2p03ZMgQc9ddd3k00dkdOnTISDKvvPKK16Oc0tGjR82FF15oqqqqzOjRoxNuyY0xZsGCBaa4uNjrMc5q/Pjx5rbbbmt33g033GCmTJni0UT+58edN4a97yp2Pn4S7sfyTU1Nqq6u1tixY9udP3bsWG3dutWjqc6uvr5ektS7d2+PJzm12bNna/z48RozZozXo5zWs88+q6KiIk2cOFF9+/bViBEjVFlZ6fVYJykuLtbLL7+sffv2SZLefvttbdmyRePGjfN4Mn/y685L7H1XsfPxk+T1AP/b4cOHFYlE1K9fv3bn9+vXT5988olHU52ZMUbz589XcXGxCgoKvB7nJGvXrtWOHTu0bds2r0c5o/fee0/l5eWaP3++7r77br355puaN2+eUlNT9f3vf9/r8dosWLBA9fX1GjJkiEKhkCKRiJYsWaJJkyZ5PZov+XHnJfbeBnY+fhKu3FsFAoF2/zbGnHReopgzZ4527dqlLVu2eD3KSerq6lRSUqIXX3xRaWlpXo9zRtFoVEVFRVq6dKkkacSIEXrnnXdUXl6eUIu+bt06rV69WmvWrNHFF1+snTt3qrS0VDk5Obr55pu9Hs+3/LTzEntvAzsfR97+VuBk4XDYhEIh88wzz7Q7f968eeaKK67waKrTmzNnjhkwYIB57733vB7llNavX28kmVAo1HaSZAKBgAmFQqalpcXrEdsMHDjQTJ06td15K1asMDk5OR5NdGoDBgwwjz76aLvzHnzwQfOlL33Jo4n8zW87bwx7bws7Hz8J9zv3lJQUFRYWqqqqqt35VVVVuuyyyzya6mTGGM2ZM0fPPPOM/vjHPyo/P9/rkU7p6quv1u7du7Vz5862U1FRkSZPnqydO3cqFAp5PWKbUaNGnfSyon379ikvL8+jiU6tsbFRwWD71QmFQon9spgE5pedl9h729j5OPL6u4tTaX1ZzC9/+UuzZ88eU1paanr27Gk++OADr0drM3PmTJOVlWU2bdpkDh482HZqbGz0erSzSsRnzRrzz5fsJCUlmSVLlph3333X/OY3vzHp6elm9erVXo/Wzs0332wuuOCCtpfFPPPMM6ZPnz7mhz/8odej+ZYfdt4Y9t42dj5+ErLcjTHmF7/4hcnLyzMpKSnm0ksvTbiXmkg65WnlypVej3ZWibjkrTZs2GAKCgpMamqqGTJkiKmoqPB6pJM0NDSYkpISM3DgQJOWlmYGDx5s7rnnHhMOh70ezdcSfeeNYe/jgZ2Pj4AxxnjzMwMAABAPCfc7dwAA0DWUOwAAjqHcAQBwDOUOAIBjKHcAABxDuQMA4JiELfdwOKwHHnhA4XDY61HOyC9zSv6ZlTnPXX75nDKnfX6Z1S9zJuzr3BsaGpSVlaX6+nplZmZ6Pc5p+WVOyT+zMue5yy+fU+a0zy+z+mXOhD1yBwAAnUO5AwDgmG7/e+7RaFQff/yxMjIyzvi3mhsaGtr9b6Lyy5ySf2Zlzo4xxujo0aPKyck56S9WJZKO7rzk/ee0o5jTPr/M6vWcHd37bv+d+4cffqjc3NzuvErAaXV1dRowYIDXY5wWOw/Yd7a97/Yj94yMDEnSgR2DlNnL3tHGVQ9MtZbVqiXdeqQk6fgVx6xnmn29rGfmvnTcembN5GTrmRe8cOajwUTSnG7vPh9pPqG31z/UtlOJKl47P+bu26xltWrKiM996Wix/V0K7bf/AJW34TPrmfum2r9/5m5MyOeBn1JTRshqXqT5hHb+7ux73+3l3vpjucxeQWVm2Fv0UEqataxWJsV6pCQplN5iPTOaZv/2JyXZX6BgD/vlnpTsn3KPptj/8fnZftTttXjtfFKy/ft8JCU+n8tguv1dCsVj50Op1jODPeIwZ7J/yj2abLfcW51t7xP3F3UAAKBTKHcAABxDuQMA4BjKHQAAx3Sq3FesWKH8/HylpaWpsLBQmzdvtj0XgATD3gP+EXO5r1u3TqWlpbrnnnv01ltv6fLLL9c3v/lN1dbWxmM+AAmAvQf8JeZyX7ZsmaZOnaof/OAHGjp0qJYvX67c3FyVl5fHYz4ACYC9B/wlpnJvampSdXW1xo4d2+78sWPHauvWraf8mHA4rIaGhnYnAP4R696z84D3Yir3w4cPKxKJqF+/fu3O79evnz755JNTfkxZWZmysrLaTrwNJeAvse49Ow94r1NPqPvf74xjjDntu+UsXLhQ9fX1bae6urrOXCUAj3V079l5wHsxvf1snz59FAqFTvpu/dChQyd9V98qNTVVqan239IQQPeIde/ZecB7MR25p6SkqLCwUFVVVe3Or6qq0mWXXWZ1MACJgb0H/CfmPxwzf/583XTTTSoqKtLXvvY1VVRUqLa2VjNmzIjHfAASAHsP+EvM5f6d73xHn376qRYvXqyDBw+qoKBAf/jDH5SXlxeP+QAkAPYe8JdO/cnXWbNmadasWbZnAZDA2HvAP3hveQAAHEO5AwDgGModAADHdOp37jZc9cBUhVLSrOW9WWb/Pa6L7ptpPVOSUl7LsJ7ZlGk9UjUzTv3GRF1y1H7mh9dFrGdKkmmxP2voiL3vp6MnJD1lLS7uxtx9m5KS7e381mWPWctqNeyR+DynIHNTD+uZ0Tg8eu/993TrmckfhaxnHri+2XqmJAWSo9Yzg3+3e/ujJyT93w5cr9VrBQAAnqPcAQBwDOUOAIBjKHcAABxDuQMA4BjKHQAAx1DuAAA4hnIHAMAxlDsAAI6h3AEAcAzlDgCAYyh3AAAcQ7kDAOAYyh0AAMdQ7gAAOIZyBwDAMZQ7AACOodwBAHAM5Q4AgGModwAAHJPk1RW3pEsmxV5e0X0z7YX9l+0PllvPlKTR06dbz/zsIvtfymhtmvXMQfe8bj2z9ulLrGdKUjAYtZ6Z1MdeZqQxbC2rOzRlBBRJCVjLG/bILGtZrXb9nxXWMyXpymnTrGf+fViy9czgoVTrmfl329/5wxsusp4pSUF7d8//lm03LtIY1oEOXI4jdwAAHEO5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjomp3MvKyjRy5EhlZGSob9++uu6667R37954zQYgAbD3gP/EVO6vvPKKZs+erTfeeENVVVVqaWnR2LFj9fnnn8drPgAeY+8B/4npnU82btzY7t8rV65U3759VV1drSuuuMLqYAASA3sP+E+X3tasvr5ektS7d+/TXiYcDisc/u930mpoaOjKVQLw2Nn2np0HvNfpJ9QZYzR//nwVFxeroKDgtJcrKytTVlZW2yk3N7ezVwnAYx3Ze3Ye8F6ny33OnDnatWuXnnzyyTNebuHChaqvr2871dXVdfYqAXisI3vPzgPe69SP5efOnatnn31Wr776qgYMGHDGy6ampio11f4fIwDQvTq69+w84L2Yyt0Yo7lz52r9+vXatGmT8vPz4zUXgATB3gP+E1O5z549W2vWrNHvfvc7ZWRk6JNPPpEkZWVlqUePHnEZEIC32HvAf2L6nXt5ebnq6+t15ZVXqn///m2ndevWxWs+AB5j7wH/ifnH8gDOLew94D+8tzwAAI6h3AEAcAzlDgCAYyh3AAAc06X3lu+K41ccUyi9xVpeymsZ1rJajZ4+3XqmJL1SUWE9c3jZLOuZvd+x/0SqA09dYj0z+6l065mSFIjD88iiSQFrWS3NJ6xldYejxccVTLf3Sc3cZP9leFdOm2Y9U5I2VVZazyx8YKb1zPPfjVrPrFkz3Hpmzn+mWM+UpEAkDplRuw8kHd17jtwBAHAM5Q4AgGModwAAHEO5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjqHcAQBwDOUOAIBjKHcAABxDuQMA4BjKHQAAx1DuAAA4hnIHAMAxlDsAAI6h3AEAcAzlDgCAYyh3AAAcQ7kDAOCYJK+u2OzrpWhamrW8pkxrUW0+uyg+n57hZbOsZ+5cuMJ65tAK+3NGa3pZzzxyYcB6piQFovYzoxbvUpGwv743D+1PV8jiztv8XLb6+7Bk+6GSCh+YaT2z+oFy65lDH7e/8yl70q1nHvmC9UhJUqjJfmbjvxiredETSdKLZ7+cvx4dAADAWVHuAAA4hnIHAMAxlDsAAI6h3AEAcEyXyr2srEyBQEClpaWWxgGQyNh5wB86Xe7btm1TRUWFhg0bZnMeAAmKnQf8o1PlfuzYMU2ePFmVlZU6//zzbc8EIMGw84C/dKrcZ8+erfHjx2vMmDFnvWw4HFZDQ0O7EwB/YecBf4n5PZ7Wrl2rHTt2aNu2bR26fFlZmRYtWhTzYAASAzsP+E9MR+51dXUqKSnR6tWrldbBt5FcuHCh6uvr2051dXWdGhRA92PnAX+K6ci9urpahw4dUmFhYdt5kUhEr776qh599FGFw2GFQqF2H5OamqrU1FQ70wLoVuw84E8xlfvVV1+t3bt3tzvv1ltv1ZAhQ7RgwYKTlhyAv7HzgD/FVO4ZGRkqKChod17Pnj2VnZ190vkA/I+dB/yJd6gDAMAxXf6LyJs2bbIwBgC/YOeBxMeROwAAjqHcAQBwDOUOAIBjKHcAABzT5SfUdVbuS8eVlGSs5dXMCFjLahWt7dg7csWq9zv2bneroRWzrGf+dfoK65n/+h/25/x85HHrmZJkovYzo2F7rwuPHm+yltUd8jZ8pqSQvTe32fvv6dayWgUPxefNd85/1/6daejjcdj52+3vfNH9M61nHrnqhPVMSQoE7D82R5rtHkNHj4c7dDmO3AEAcAzlDgCAYyh3AAAcQ7kDAOAYyh0AAMdQ7gAAOIZyBwDAMZQ7AACOodwBAHAM5Q4AgGModwAAHEO5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjqHcAQBwDOUOAIBjKHcAABxDuQMA4Jgkr664ZnKygj2S7QUeDdjL+i+D7nndeqYkHXjqEuuZ0Zpe1jP/9T9mWc98+4crrGeOKp1hPVOSZIz1yIDFyJbmkD60Fxd3+6ZmKNgjzVpe8kcha1mt8u+Oz87XrBluPTNlT7r1zKL7Z1rP3L643HrmFTOnW8+Ml0DEbl5Lc5LqOnA5jtwBAHAM5Q4AgGModwAAHEO5AwDgGModAADHUO4AADgm5nL/6KOPNGXKFGVnZys9PV3Dhw9XdXV1PGYDkCDYe8BfYnqd+2effaZRo0bpqquu0vPPP6++ffuqpqZG5513XpzGA+A19h7wn5jK/eGHH1Zubq5WrlzZdt6gQYNszwQggbD3gP/E9GP5Z599VkVFRZo4caL69u2rESNGqLKy8owfEw6H1dDQ0O4EwD9i3Xt2HvBeTOX+3nvvqby8XBdeeKFeeOEFzZgxQ/PmzdOvfvWr035MWVmZsrKy2k65ubldHhpA94l179l5wHsxlXs0GtWll16qpUuXasSIEbr99ts1bdo0lZef/r2DFy5cqPr6+rZTXV1H3hUXQKKIde/ZecB7MZV7//799eUvf7ndeUOHDlVtbe1pPyY1NVWZmZntTgD8I9a9Z+cB78VU7qNGjdLevXvbnbdv3z7l5eVZHQpA4mDvAf+JqdzvuOMOvfHGG1q6dKn279+vNWvWqKKiQrNnz47XfAA8xt4D/hNTuY8cOVLr16/Xk08+qYKCAj344INavny5Jk+eHK/5AHiMvQf8J6bXuUvShAkTNGHChHjMAiBBsfeAv/De8gAAOIZyBwDAMZQ7AACOifl37rZc8EJASckBa3kfXhexltWq9ulLrGdKUvZT6dYzj1xo73PZ6vORx61njiqdYT3zteWPWc+UpOpwk/XMzY0XWcs6caxF2/6ftbi4y91olJRsrOUduL7ZWlarwxvsfX3+p5z/TLGeeeQL1iN15KoT1jOvmDndeuar5RXWMyWppvmY9cx3m7Ot5jUejWjixrNfjiN3AAAcQ7kDAOAYyh0AAMdQ7gAAOIZyBwDAMZQ7AACOodwBAHAM5Q4AgGModwAAHEO5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjqHcAQBwDOUOAIBjKHcAABxDuQMA4BjKHQAAx1DuAAA4hnIHAMAxSV4PYItpCVjPDAaj1jMlKWDikBmHUU08br6xf+Orw03WMyWpMDXFeubucKO1rOOhFmtZfhRItn8HDdp/GJEkBSL2M0NxuNsH4vHgFAc1zcfikvuF5F7WM99tth7ZIRy5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjomp3FtaWnTvvfcqPz9fPXr00ODBg7V48WJFo/F5VjkA77H3gP/E9FK4hx9+WI899phWrVqliy++WNu3b9ett96qrKwslZSUxGtGAB5i7wH/iancX3/9dX3729/W+PHjJUmDBg3Sk08+qe3bt8dlOADeY+8B/4npx/LFxcV6+eWXtW/fPknS22+/rS1btmjcuHGn/ZhwOKyGhoZ2JwD+Eeves/OA92I6cl+wYIHq6+s1ZMgQhUIhRSIRLVmyRJMmTTrtx5SVlWnRokVdHhSAN2Lde3Ye8F5MR+7r1q3T6tWrtWbNGu3YsUOrVq3SI488olWrVp32YxYuXKj6+vq2U11dXZeHBtB9Yt17dh7wXkxH7nfeeafuuusuffe735UkXXLJJTpw4IDKysp08803n/JjUlNTlZqa2vVJAXgi1r1n5wHvxXTk3tjYqGCw/YeEQiFeEgM4jL0H/CemI/drr71WS5Ys0cCBA3XxxRfrrbfe0rJly3TbbbfFaz4AHmPvAf+Jqdx//vOf67777tOsWbN06NAh5eTk6Pbbb9f9998fr/kAeIy9B/wnpnLPyMjQ8uXLtXz58jiNAyDRsPeA//De8gAAOIZyBwDAMZQ7AACOodwBAHBMTE+os6k5Pahoir3vLUJH7H+fktQnPq/jjSYF4pBpPVLRcMh6ZsBYj9Tmxovsh0raHW60nnlL5iFrWQ2BqOZYS4u/poyQosn27lPBv9u/fyrbfqQkBaL27/iN/2I/M9Js/3E0ELEeqXeb4/OFerfZfua/pYet5jVEOtZLHLkDAOAYyh0AAMdQ7gAAOIZyBwDAMZQ7AACOodwBAHAM5Q4AgGModwAAHEO5AwDgGModAADHUO4AADiGcgcAwDGUOwAAjqHcAQBwDOUOAIBjKHcAABxDuQMA4BjKHQAAx1DuAAA4Jqm7r9AYI0mKNJ+wmhu1GydJijSG7YdKarF82yUpErb/fVr0eJP1zJbmkPXME8darGdK0vGQ/dyGQNRe1rF/ZrXuVKJi5+Oz89ET9h++o8ft3/6WZvtzNh6NWM+Ml4aIvZ2XOr73AdPNjwwffvihcnNzu/MqAafV1dVpwIABXo9xWuw8YN/Z9r7byz0ajerjjz9WRkaGAoHAaS/X0NCg3Nxc1dXVKTMzsxsnjI1f5pT8MytzdowxRkePHlVOTo6CwcT9DVtHd17y/nPaUcxpn19m9XrOju59t/9YPhgMxnSUkZmZmdBf6FZ+mVPyz6zMeXZZWVmeXG8sYt15ia+9bX6ZU/LPrIm+94n77T4AAOgUyh0AAMckbLmnpqbqRz/6kVJTU70e5Yz8Mqfkn1mZ89zll88pc9rnl1n9Mme3P6EOAADEV8IeuQMAgM6h3AEAcAzlDgCAYyh3AAAcQ7mj0z744AMFAgHt3LnT61EA/A/GGE2fPl29e/fu0I6yy+7p9neoAwDE18aNG/XEE09o06ZNGjx4sPr06eP1SOhmlPs5qqmpSSkpKV6PASAOampq1L9/f1122WVejwKP8GP5c8SVV16pOXPmaP78+erTp4++8Y1vaM+ePRo3bpx69eqlfv366aabbtLhw4fbPmbjxo0qLi7Weeedp+zsbE2YMEE1NTUe3goAZ3PLLbdo7ty5qq2tVSAQ0KBBg2Le5Wg0qmnTpumiiy7SgQMHJEkbNmxQYWGh0tLSNHjwYC1atEgtLfH5c8voOsr9HLJq1SolJSXptdde049//GONHj1aw4cP1/bt27Vx40b97W9/04033th2+c8//1zz58/Xtm3b9PLLLysYDOr6669XNGr37xMDsOdnP/uZFi9erAEDBujgwYPatm1bTLvc1NSkG2+8Udu3b9eWLVuUl5enF154QVOmTNG8efO0Z88ePf7443riiSe0ZMkSD24hOsTgnDB69GgzfPjwtn/fd999ZuzYse0uU1dXZySZvXv3njLj0KFDRpLZvXu3McaY999/30gyb731VtzmBhC7n/70pyYvL++0///pdnnz5s1mzJgxZtSoUebIkSNtl7/88svN0qVL22X8+te/Nv3794/L/Og6jtzPIUVFRW3/XV1drT/96U/q1atX22nIkCGS1PbjupqaGn3ve9/T4MGDlZmZqfz8fElSbW1t9w8PoNM6usuTJk3SsWPH9OKLL7b7s6LV1dVavHhxu8eLadOm6eDBg2psbOzW24KO4Ql155CePXu2/Xc0GtW1116rhx9++KTL9e/fX5J07bXXKjc3V5WVlcrJyVE0GlVBQYGampq6bWYAXdfRXR43bpxWr16tN954Q1//+tfbzo9Go1q0aJFuuOGGk7LT0tLiPj9iR7mfoy699FL99re/1aBBg5SUdPLd4NNPP9Vf//pXPf7447r88sslSVu2bOnuMQF0USy7PHPmTBUUFOhb3/qWfv/732v06NGS/vl4sXfvXn3xi1/strnRNZT7OWr27NmqrKzUpEmTdOedd6pPnz7av3+/1q5dq8rKSp1//vnKzs5WRUWF+vfvr9raWt11111ejw0gRrHu8ty5cxWJRDRhwgQ9//zzKi4u1v33368JEyYoNzdXEydOVDAY1K5du7R792499NBD3Xhr0FH8zv0clZOTo9dee02RSETXXHONCgoKVFJSoqysLAWDQQWDQa1du1bV1dUqKCjQHXfcoZ/85Cdejw0gRp3Z5dLSUi1atEjjxo3T1q1bdc011+i5555TVVWVRo4cqa9+9atatmyZ8vLyuulWIFb8PXcAABzDkTsAAI6h3AEAcAzlDgCAYyh3AAAcQ7kDAOAYyh0AAMdQ7gAAOIZyBwDAMZQ7AACOodwBAHAM5Q4AgGP+P/uGLq9MlxepAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_dfs(\n",
    "    data_all,\n",
    "    data_generated,\n",
    "    table_groupby=[\"T\"],\n",
    "    figsize=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1eabe6",
   "metadata": {},
   "source": [
    "Note the remarkable quality of the generated data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
